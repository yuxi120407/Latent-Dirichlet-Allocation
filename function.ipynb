{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 15 10:34:27 2018\n",
    "\n",
    "@author: yuxi\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "import glob\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "def newtxt(path_txt,path_image,crop_length,crop_width):\n",
    "    # load the true demension of the image\n",
    "    image = imread(path_image)\n",
    "    true_length = image.shape[1]\n",
    "    true_width = image.shape[0]\n",
    "    \n",
    "    #read the orginal demension of the image\n",
    "    txtfile = open(path_txt)\n",
    "    firstline = txtfile.readlines()[0].split(\",\") \n",
    "    original_length = int(firstline[2])\n",
    "    original_width = int(firstline[3])\n",
    "    txtfile.close()\n",
    "    \n",
    "    #read the number of the random points in the image\n",
    "    txtfile = open(path_txt)\n",
    "    count_points = int(txtfile.readlines()[5])\n",
    "    txtfile.close()\n",
    "    \n",
    "    #read the corrdinate of the image\n",
    "    txtfile = open(path_txt)\n",
    "    data = txtfile.readlines()[6:6+count_points]\n",
    "    corrdinate = np.zeros([count_points,2],dtype = np.int)\n",
    "    for n in range(count_points): \n",
    "        data1 = data[n].split(\",\")\n",
    "        corrdinate[n,0] =int(int(data1[0])*true_length/original_length)\n",
    "        corrdinate[n,1] =int(int(data1[1])*true_width/original_width)\n",
    "    txtfile.close()\n",
    "    \n",
    "    #read the label of each points and encode the label\n",
    "    txtfile = open(path_txt)\n",
    "    label_encode = np.zeros(count_points)\n",
    "    label = txtfile.readlines()[6+count_points:6+count_points+count_points]\n",
    "    for m in range(count_points):\n",
    "        label1 = label[m].split(\",\")\n",
    "        label2 = label1[1]\n",
    "        new_l = label2.replace('\\\"', '')\n",
    "        #coral\n",
    "        if ((new_l==\"Agalg\") or (new_l==\"Aga\") or (new_l==\"Agaf\") or (new_l==\"Col\") or (new_l==\"Helc\") or (new_l==\"Mdrc\") or (new_l==\"Mdrcb\") or (new_l==\"Mdrsd\")or (new_l==\"Mdrsf\") or (new_l==\"Man\")or (new_l==\"Mon\")or (new_l==\"Ocu\")or (new_l==\"Sco\")or (new_l==\"Sol\")or (new_l==\"Ste\")or (new_l==\"STY\")):\n",
    "            label_encode[m] = 0\n",
    "        #dead coral plate\n",
    "        elif (new_l==\"DCP\"):\n",
    "            label_encode[m] = 1\n",
    "        #rock\n",
    "        elif (new_l==\"ROC\"):\n",
    "            label_encode[m] = 2\n",
    "        #red alage\n",
    "        elif ((new_l==\"CCA\") or (new_l==\"Amph\") or (new_l==\"Bot\") or (new_l==\"Haly\") or (new_l==\"Kal\") or (new_l==\"Mar\") or (new_l==\"PEY\") or (new_l==\"RHO\") or (new_l==\"RHbl\")) :\n",
    "            label_encode[m] = 3\n",
    "        #green alage\n",
    "        elif ((new_l==\"Ana\") or (new_l==\"Cau\") or (new_l==\"Caup\") or (new_l==\"Caur\") or (new_l==\"Caus\") or (new_l==\"Chae\") or (new_l==\"CHL\") or (new_l==\"Cod\") or (new_l==\"Codin\") or (new_l==\"Hal\") or (new_l==\"Halc\") or (new_l==\"Hald\") or (new_l==\"Halt\") or (new_l==\"Micr\") or (new_l==\"Ulva\") or (new_l==\"Venv\") or (new_l==\"Verp\")):\n",
    "            label_encode[m] = 4 \n",
    "        else:\n",
    "            label_encode[m] = 5\n",
    "    txtfile.close()\n",
    "    #save the encode labeled pixel data into new files\n",
    "    name_image = path_image.split(\"/\")[2] \n",
    "    name_txt = name_image.split(\".\")[0]\n",
    "    with open(str('2015-image-data - Copy/')+name_txt+str('.txt'), 'w+') as newtxtfile:\n",
    "        newtxtfile.write(name_image+str('\\n'))\n",
    "        newtxtfile.write('x,y,label\\n')\n",
    "        for i in range(count_points):\n",
    "            x = corrdinate[i,0]\n",
    "            y = corrdinate[i,1]\n",
    "            label = int(label_encode[i])\n",
    "            newtxtfile.write('{0},{1},{2}\\n'.format(x,y,label))\n",
    "        newtxtfile.close()\n",
    "    #transfer the pixel data into crop iamge data\n",
    "    all_image = np.zeros([count_points,crop_length,crop_width,3],dtype=np.uint8)\n",
    "    crop_x = int(crop_length/2)\n",
    "    crop_y = int(crop_width/2)\n",
    "    for i in range(count_points):\n",
    "        if(corrdinate[i,0]-crop_x <0):\n",
    "            corrdinate[i,0] = crop_x\n",
    "        elif(corrdinate[i,1]-crop_y <0):\n",
    "            corrdinate[i,1] = crop_y\n",
    "        elif(corrdinate[i,0]+crop_x >true_length):\n",
    "            corrdinate[i,0] = true_length-crop_x\n",
    "        elif(corrdinate[i,1]+crop_y >true_width):\n",
    "            corrdinate[i,1] =true_width-crop_y\n",
    "        all_image[i,:,:,:] = image[corrdinate[i,1]-crop_y:corrdinate[i,1]+crop_y,corrdinate[i,0]-crop_x:corrdinate[i,0]+crop_x]\n",
    "    return all_image, label_encode\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "def newimagedata(crop_length,crop_width):\n",
    "    all_label = np.zeros(1)\n",
    "    image_data = np.zeros([1,crop_length,crop_width,3],dtype=np.uint8)\n",
    "    read_files = glob.glob(\"./2015-image-data - Copy/*.txt\")\n",
    "    #length = len(read_files)\n",
    "    for name in read_files:\n",
    "        name = name.split(\"\\\\\")[1]\n",
    "        name = name.split(\".\")[0]\n",
    "        path_txt = str('./2015-image-data - Copy/')+name+str('.txt')\n",
    "        path_image = str('./2015image/')+name+str('.jpg')\n",
    "        new_image_data,label = newtxt(path_txt,path_image,crop_length,crop_width)\n",
    "        all_label = np.hstack((all_label,label))\n",
    "        image_data = np.vstack((image_data,new_image_data))\n",
    "    final_data = image_data[1:,:,:,:]\n",
    "    final_label = all_label[1:]\n",
    "    return final_data,final_label\n",
    "#%%\n",
    "def create_plots(history):\n",
    "    fig = plt.figure(figsize=(5,10))\n",
    "    ax = fig.add_subplot(*[2,1,1])\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    ax.set_title('accuracy of CNN')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    #plt.savefig('accuracy.png')\n",
    "    #plt.clf()\n",
    "    #plt.show()\n",
    "    \n",
    "    ax = fig.add_subplot(*[2,1,2])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss of CNN')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    #plt.savefig('loss.png')\n",
    "    #plt.clf()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(confusionmatrix, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        confusionmatrix = confusionmatrix.astype('float') / confusionmatrix.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(confusionmatrix)\n",
    "\n",
    "    plt.imshow(confusionmatrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = confusionmatrix.max() / 2.\n",
    "    for i, j in itertools.product(range(confusionmatrix.shape[0]), range(confusionmatrix.shape[1])):\n",
    "        plt.text(j, i, format(confusionmatrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if confusionmatrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#%%\n",
    "def shuffle(data,label):\n",
    "    data_shape = data.shape\n",
    "    data = data.reshape(-1,data_shape[1]*data_shape[2]*data_shape[3])\n",
    "    Z = np.column_stack((data,label))\n",
    "    np.random.shuffle(Z)\n",
    "    fully_data = Z[:,:,-1]\n",
    "    shuffle_label = Z[:,-1]\n",
    "    shuffle_data = fully_data.reshape(-1,30,30,3)\n",
    "    return shuffle_data,shuffle_label\n",
    "    \n",
    "    \n",
    "#%%six convolutional layers cnn model\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(30,30,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))       \n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25)) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "#%%eight convolutional layers cnn model\n",
    "def cnn_model2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(30,30,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))       \n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25)) \n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "#%%four convolutional layers\n",
    "def cnn_model1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(30,30,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))       \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def read_generate_data(txtfolder_name,imagefloder_name,image_x,image_y):\n",
    "    all_count = 1\n",
    "    all_label = np.zeros(1,dtype=np.int)\n",
    "    image_data = np.zeros([1,30,30,3],dtype=np.uint8)\n",
    "    read_files = glob.glob(str('./')+txtfolder_name+str('/*.txt'))\n",
    "    for name in read_files:\n",
    "        name = name.split(\"\\\\\")[1]\n",
    "        name = name.split(\".\")[0]\n",
    "        path_txt = str('./')+txtfolder_name+str('/')+name+str('.txt')\n",
    "        path_image = str('./')+ imagefloder_name+str('/')+name+str('.jpg')\n",
    "        new_image_data,label = generate_signal_imagedata(path_txt,path_image,image_x,image_y)\n",
    "        all_label = np.hstack((all_label,label))\n",
    "        image_data = np.vstack((image_data,new_image_data))\n",
    "        print(\"Image {0} is finish \".format(all_count))\n",
    "        all_count = all_count+1\n",
    "    final_data = image_data[1:,:,:,:]\n",
    "    final_label = all_label[1:]\n",
    "    return final_data,final_label\n",
    "\n",
    "def generate_signal_imagedata(path_txt,path_image,image_x,image_y):\n",
    "    txt_file = open(path_txt)\n",
    "    text = txt_file.readlines()[2:]\n",
    "    count_points = len(text)\n",
    "    \n",
    "    crop_length = 30\n",
    "    crop_width = 30\n",
    "    all_image = np.zeros([count_points,crop_length,crop_width,3],dtype=np.uint8)\n",
    "    label = np.zeros(count_points,dtype=np.int)\n",
    "    crop_x = int(crop_length/2)\n",
    "    crop_y = int(crop_width/2)\n",
    "    image = imread(path_image)\n",
    "    for i in range(count_points):\n",
    "        text_piece = text[i]\n",
    "        text_element = text_piece.split(',')\n",
    "        l_x = int(float(text_element[0]))\n",
    "        l_y = int(float(text_element[1]))\n",
    "        label[i] = int(text_element[2])\n",
    "        if(l_x-crop_x <0):\n",
    "            l_x = crop_x\n",
    "        if(l_y-crop_y <0):\n",
    "            l_y = crop_y\n",
    "        if(l_x+crop_x >image_y):\n",
    "            l_x = image_y-15\n",
    "        if(l_y+crop_y >image_x):\n",
    "            l_y =image_x-15\n",
    "        all_image[i,:,:,:] = image[l_y-15:l_y+15,l_x-15:l_x+15]\n",
    "    txt_file.close()\n",
    "    return all_image,label\n",
    "#%%\n",
    "#original_data,original_label = newimagedata(30,30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
